

# 项目协作指南与Git工作流程

大家好，项目的前期框架搭建工作已经顺利完成，现在我们需要分工协作，开始核心的模型训练与评估。

以下是目前的项目进展、各位需要完成的任务、以及我们的协作方式，请大家仔细阅读。

## 本地环境准备 (必做步骤)

在开始任何工作之前，**每个人都必须独立完成以下本地环境准备工作**。由于大型数据集和处理后的数据文件没有上传到GitHub仓库，这些步骤是保证你能够成功运行代码的前提。

#### **第一步：下载数据集**

- 请从这个链接下载新闻数据集：https://github.com/Webhose/free-news-datasets?tab=readme-ov-file
- 下载后解压，你会得到一个名为 `free-news-datasets-master` 的文件夹。

#### **第二步：放置数据集**

- **重要**：请确保 `free-news-datasets-master` 文件夹与你即将克隆的项目文件夹 `7012GP` **位于同一级目录**下。你的文件夹结构应该如下所示：

  ```
  - /你的工作区/
      ├── free-news-datasets-master/   <-- 你下载并解压的数据集
      └── news_classification_project  <-- 你接下来要克隆的项目代码
  ```

#### **第三步：克隆代码库并安装依赖**

- 打开终端（Terminal 或 Git Bash），进入你的工作区，然后克隆我们的项目代码：

  ```
  git clone https://github.com/Fizz-Wang/7012GP.git
  cd 7012GP
  ```

- 安装项目所需的所有Python库：

  ```
  推荐用PyCharm一键生成
  ```

#### **第四步：生成本地数据文件**

- 现在，你需要依次运行两个脚本来生成模型训练必需的数据文件。

- **生成 CSV 文件**:

  ```
  python 01_load_data.py
  ```

  运行成功后，你应该会在 `7012GP/` 文件夹里看到 `news_dataset.csv` 文件。

- **生成 PKL 文件**:

  ```
  python classical_models/preprocess.py
  ```

  运行成功后，你应该会在 `7012GP/results/` 文件夹里看到 `processed_data.pkl` 文件。

**完成以上所有步骤后，你的本地环境才算准备就绪！**

## 关于GitHub权限 (非常重要)

作为仓库的拥有者，我需要将大家添加为项目的“协作者”(Collaborator)，这样你们才有权限推送自己的代码分支。

**请大家将自己的 GitHub 用户名发给我。**

我会按照以下步骤为大家添加权限：

1. 进入我们的项目主页：https://github.com/Fizz-Wang/7012GP
2. 点击 `Settings` -> `Collaborators`。
3. 通过你们的用户名搜索并添加你们。
4. 你们会收到一封邀请邮件，**请务必点击邮件中的链接接受邀请**。接受后，你们才能开始推送代码。

## 我已经完成的工作 (项目基础)

- **数据处理流水线**: 我已经建立了一个完整的数据加载和预处理流程。这个流程会读取原始的JSON新闻数据，进行文本清洗，最后通过TF-IDF进行向量化，并将处理好的训练集和测试集统一保存到 `processed_data.pkl` 文件中。
- **通用训练框架**: 我为大家创建了一个通用的模型训练脚本框架。这个框架可以被直接复制到你们各自负责的模型文件中。它的设计思路是“**一次运行，一次实验**”，非常便于我们系统地测试和记录不同参数的效果。
- **GitHub 仓库初始化**: 我已经创建了项目的中央代码仓库，并上传了初始框架。

## 各位需要完成的任务 (核心实验部分)

现在，请大家领取各自负责的模型，并开始进行实验。我们的分工如下：

- **逻辑回归 (Logistic Regression)** - Shuqi
- **支持向量机 (Support Vector Machine - SVM)** - Shibo
- **决策树 (Decision Tree)** - Jiarui

你们每个人的具体任务都一样，请严格按照以下步骤操作：

#### 第一步：配置你的训练脚本

- 将我提供的**通用框架**代码复制到你负责的脚本文件中（例如 `02_train_logistic.py`）。
- 在文件顶部的【关键任务 A】部分，填写你负责的**模型信息**（比如模型名称和导入的类）。

#### 第二步：进行参数实验

- 这是我们项目的**核心**。你需要多次运行你的脚本，每次运行前，都要在【关键任务 B】部分**手动修改模型的超参数**。
- **目标**：通过尝试不同的参数组合（例如，调整逻辑回归的`C`值，或决策树的`max_depth`），找到能让模型性能达到最佳的配置。

#### 第三步：记录与分析你的发现 (至关重要)

- 每次运行脚本后，系统都会在 `results/[你的模型名称]/` 文件夹下生成一个包含**模型(.joblib)和评估报告(.txt)**的文件。
- 你们的核心任务就是**记录下你们的实验过程**。我建议你们可以自己创建一个简单的表格或文档，记录每一组尝试的**参数**以及从`.txt`报告中得到的核心**评估结果** (Accuracy, Precision, Recall, F-score, AUC)。
- **为什么这很重要？** 这些记录是后续撰写项目报告中 **“Methodology” (方法论)** 和 **“Results and Discussion” (结果与讨论)** 章节的**直接素材**。没有这些详细的实验记录，我们的论文将言之无物。

## 如何使用 Git 和 GitHub 进行协作 (重要)

为了避免代码冲突并保持项目整洁，我们将遵循一个标准的分支开发工作流。

#### 第 1 步：创建你的个人开发分支 (Branch)

**每次**开始一项新任务（比如测试一组新参数）前，都应该创建一个新的分支。这可以确保我们的主分支 (`main`) 永远是稳定可用的。

```
# 首先，确保你的主分支是最新版本
git checkout main
git pull origin main

# 然后，创建一个以你名字和任务为名的新分支并切换过去
# 格式: git checkout -b [你的名字]/[任务描述]
git checkout -b zhangsan/tune-logistic-regression-C10
```

#### 第 2 步：修改代码并进行实验

现在你可以在这个新分支上安全地修改你负责的脚本文件，比如更改参数、运行实验等。

#### 第 3 步：提交你的更改 (Commit)

当你完成一次实验并生成了新的结果文件后，你需要提交你的代码更改。

```
# 添加所有更改到暂存区
git add .

# 创建一个提交，并写清楚这次提交做了什么
git commit -m "feat: Tune Logistic Regression with C=10 and save results"
```

#### 第 4 步：推送你的分支到 GitHub (Push)

将你的本地分支和上面的提交推送到远程仓库。

```
# 格式: git push origin [你的分支名]
git push origin zhangsan/tune-logistic-regression-C10
```

#### 第 5 步：创建合并请求 (Pull Request)

- 推送到 GitHub 后，在浏览器中打开我们的项目主页。
- 你会看到一个黄色的提示条，提示你刚刚推送了一个新分支。点击 "Compare & pull request" 按钮。
- 填写标题和描述，说明你完成了什么工作，然后创建 Pull Request。
- 这样我（或其他组员）就可以审查你的代码，确认没有问题后，再将其合并到主分支 `main` 中。

## 时间规划与后续步骤

请大家先集中精力完成各自模型的**代码实验和结果记录**。不用担心论文的写作，我会在此期间开始搭建报告的整体结构。

当我们收集到足够多、足够好的实验结果后，我会召集大家，将你们的发现整合进最终的报告中。

大家开始吧！如果在配置和运行脚本或使用 Git 时遇到任何问题，随时在群里提出。
